{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7acc7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:10.174373Z",
     "start_time": "2022-05-10T03:33:06.591840Z"
    },
    "id": "3c7acc7f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda86034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:12.678356Z",
     "start_time": "2022-05-10T03:33:10.443851Z"
    },
    "id": "cda86034",
    "outputId": "c01dba00-80d5-4006-a383-064301049830"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Lower_Neg_Review</th>\n",
       "      <th>Lower_Pos_Review</th>\n",
       "      <th>Negative_Review_Clean</th>\n",
       "      <th>Positive_Review_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/17</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>my room was dirty and i was afraid to walk ba...</td>\n",
       "      <td>great location in nice surroundings the bar a...</td>\n",
       "      <td>my room was dirty and i was afraid to walk ba...</td>\n",
       "      <td>great location in nice surroundings the bar a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/17/17</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Cleaner did not change our sheet and duvet ev...</td>\n",
       "      <td>33</td>\n",
       "      <td>1403</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[' Leisure trip ', ' Group ', ' Duplex Twin Ro...</td>\n",
       "      <td>17</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>cleaner did not change our sheet and duvet ev...</td>\n",
       "      <td>the room is spacious and bright the hotel is ...</td>\n",
       "      <td>cleaner did not change our sheet and duvet ev...</td>\n",
       "      <td>the room is spacious and bright the hotel is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/17/17</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Apart from the price for the brekfast Everyth...</td>\n",
       "      <td>11</td>\n",
       "      <td>1403</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>17</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>apart from the price for the brekfast everyth...</td>\n",
       "      <td>good location set in a lovely park friendly s...</td>\n",
       "      <td>apart from the price for the brekfast everyth...</td>\n",
       "      <td>good location set in a lovely park friendly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/7/17</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nothing all great</td>\n",
       "      <td>5</td>\n",
       "      <td>1403</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[' Leisure trip ', ' Group ', ' Duplex Double ...</td>\n",
       "      <td>27</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>nothing all great</td>\n",
       "      <td>rooms were stunningly decorated and really sp...</td>\n",
       "      <td>nothing all great</td>\n",
       "      <td>rooms were stunningly decorated and really sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/6/17</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>The floor in my room was filfy dirty Very bas...</td>\n",
       "      <td>28</td>\n",
       "      <td>1403</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>28</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>the floor in my room was filfy dirty very bas...</td>\n",
       "      <td>comfy bed good location</td>\n",
       "      <td>the floor in my room was filfy dirty very bas...</td>\n",
       "      <td>comfy bed good location</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                                      Hotel_Address  \\\n",
       "0             0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1             1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2             2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3             3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4             4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194     7/31/17            7.7  Hotel Arena   \n",
       "1                           194     7/17/17            7.7  Hotel Arena   \n",
       "2                           194     7/17/17            7.7  Hotel Arena   \n",
       "3                           194      7/7/17            7.7  Hotel Arena   \n",
       "4                           194      7/6/17            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "1      United Kingdom    Cleaner did not change our sheet and duvet ev...   \n",
       "2      United Kingdom    Apart from the price for the brekfast Everyth...   \n",
       "3      United Kingdom                                  Nothing all great    \n",
       "4      United Kingdom    The floor in my room was filfy dirty Very bas...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  ...  \\\n",
       "0                                210                     1403  ...   \n",
       "1                                 33                     1403  ...   \n",
       "2                                 11                     1403  ...   \n",
       "3                                  5                     1403  ...   \n",
       "4                                 28                     1403  ...   \n",
       "\n",
       "  Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                          1             3.8   \n",
       "1                                          6             4.6   \n",
       "2                                          1            10.0   \n",
       "3                                          2            10.0   \n",
       "4                                          7             4.6   \n",
       "\n",
       "                                                Tags  days_since_review  \\\n",
       "0  [' Leisure trip ', ' Solo traveler ', ' Duplex...                  3   \n",
       "1  [' Leisure trip ', ' Group ', ' Duplex Twin Ro...                 17   \n",
       "2  [' Leisure trip ', ' Couple ', ' Duplex Double...                 17   \n",
       "3  [' Leisure trip ', ' Group ', ' Duplex Double ...                 27   \n",
       "4  [' Leisure trip ', ' Solo traveler ', ' Duplex...                 28   \n",
       "\n",
       "         lat       lng                                   Lower_Neg_Review  \\\n",
       "0  52.360576  4.915968   my room was dirty and i was afraid to walk ba...   \n",
       "1  52.360576  4.915968   cleaner did not change our sheet and duvet ev...   \n",
       "2  52.360576  4.915968   apart from the price for the brekfast everyth...   \n",
       "3  52.360576  4.915968                                 nothing all great    \n",
       "4  52.360576  4.915968   the floor in my room was filfy dirty very bas...   \n",
       "\n",
       "                                    Lower_Pos_Review  \\\n",
       "0   great location in nice surroundings the bar a...   \n",
       "1   the room is spacious and bright the hotel is ...   \n",
       "2   good location set in a lovely park friendly s...   \n",
       "3   rooms were stunningly decorated and really sp...   \n",
       "4                           comfy bed good location    \n",
       "\n",
       "                               Negative_Review_Clean  \\\n",
       "0   my room was dirty and i was afraid to walk ba...   \n",
       "1   cleaner did not change our sheet and duvet ev...   \n",
       "2   apart from the price for the brekfast everyth...   \n",
       "3                                 nothing all great    \n",
       "4   the floor in my room was filfy dirty very bas...   \n",
       "\n",
       "                               Positive_Review_Clean  \n",
       "0   great location in nice surroundings the bar a...  \n",
       "1   the room is spacious and bright the hotel is ...  \n",
       "2   good location set in a lovely park friendly s...  \n",
       "3   rooms were stunningly decorated and really sp...  \n",
       "4                           comfy bed good location   \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel = pd.read_csv('uk_hotel.csv', index_col = 0)\n",
    "hotel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9347b177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:14.525734Z",
     "start_time": "2022-05-10T03:33:14.514877Z"
    },
    "id": "9347b177",
    "outputId": "501421ae-0d31-4da5-ee04-35daef41e439"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124881, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e4878c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:16.273558Z",
     "start_time": "2022-05-10T03:33:16.260568Z"
    },
    "id": "53e4878c"
   },
   "outputs": [],
   "source": [
    "## https://gist.github.com/gaurav5430/9fce93759eb2f6b1697883c3782f30de#file-nltk-lemmatize-sentences-py\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    '''convert nltk tag to wordnet tag'''\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    '''perform lemmatization based on part of speech'''\n",
    "    # tokenize the sentence and find the POS tag for each token (get part of speech)\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    # tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            # if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            # else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88984462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:19.990265Z",
     "start_time": "2022-05-10T03:33:19.980507Z"
    },
    "id": "88984462"
   },
   "outputs": [],
   "source": [
    "def remove(lines: pd.Series):\n",
    "    '''tokenize each line and remove the stopwords'''\n",
    "    l = []\n",
    "    for line in lines:\n",
    "        words = nltk.word_tokenize(line)\n",
    "        new_line = ''\n",
    "        for word in words:\n",
    "            if word not in stopword_list:\n",
    "                new_line += word + ' '\n",
    "        l.append(new_line)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e917234",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:23.017560Z",
     "start_time": "2022-05-10T03:33:22.998382Z"
    },
    "id": "9e917234",
    "outputId": "b0fd98f9-bcf3-4e32-f2a1-4e64c90fbde0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hasn't\", 'here', \"aren't\", 'wouldn', 're', 'how', 'hers', 'has', 'the', 'you', 'don', 'shan', 'which', 'aren', 'once', 'from', \"you'll\", \"it's\", 'under', 'only', 'further', \"mightn't\", 'yourself', 'had', 'are', 'does', \"you'd\", 'over', 'too', 'of', 'd', 'yourselves', 'but', 'off', 'down', 'during', 'such', 'she', \"doesn't\", \"shan't\", 'and', 'before', 'then', 'mustn', 'been', 'again', 'y', \"isn't\", 'below', 'a', 's', 'as', 'mightn', \"won't\", 'it', 'he', 'to', 'up', 'this', 'into', 'at', 'hasn', 'they', 'ours', 'was', 'i', 'haven', 'what', 'wasn', 'him', \"shouldn't\", 'itself', 'other', 've', 'between', 'there', 'his', 'whom', 'few', 'is', \"wouldn't\", 'yours', \"mustn't\", 'theirs', 'if', 'ain', 'by', 'each', 'them', 'most', 'won', 'your', \"wasn't\", 'or', 'now', 'an', 'when', 'for', 'those', 'her', 'myself', 'after', 'where', 'having', 'nor', 'himself', 'than', 'doesn', \"didn't\", 'about', \"should've\", 'some', 'more', 'needn', 'that', 'until', 'both', 'with', 'should', 'weren', 'we', 'being', \"you've\", 'in', 'doing', \"you're\", 'll', \"weren't\", 'were', 'because', 'while', 'have', \"couldn't\", 'my', 'me', 'any', 'couldn', 'herself', 'am', 'just', 'these', 'isn', \"that'll\", \"hadn't\", 'our', 'will', 'on', 'did', 'its', 'not', 'shouldn', 'very', 't', 'their', 'do', 'didn', 'so', 'ourselves', 'who', 'same', 'themselves', \"she's\", 'own', 'why', 'all', 'through', 'no', \"needn't\", 'against', 'be', 'm', 'out', 'above', \"don't\", 'o', 'hadn', 'ma', 'can', \"haven't\"}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113719f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:25.069503Z",
     "start_time": "2022-05-10T03:33:24.585836Z"
    },
    "id": "113719f8",
    "outputId": "f5208e24-e505-488e-ecb6-85bab31db5a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'here', 'has', 'inc', 'under', 'further', 'never', 'yourself', 'hereafter', 'does', 'too', 'say', 'yourselves', 'get', 'hundred', 'wherein', 'whereas', 'down', 'otherwise', 'fill', 'then', 'call', 'someone', 'everywhere', 'at', 'ours', 'was', 'ten', 'fifteen', 'nine', 'i', 'him', 'neither', 'co', 'between', 'sometimes', 'con', 'regarding', 'yours', 'if', 'fire', 'made', 'across', 'km', 'make', 'various', 'seems', 'name', 'than', 'himself', 'doesn', 'used', 'sometime', 'some', 'both', 'until', 'we', 'around', 'thereafter', 'every', 'side', 'although', 'my', 'any', 'amount', 'empty', 'namely', 'however', 'will', 'thru', 'de', 'not', 'show', 'same', 'themselves', 'three', 'really', 'through', 'next', 'became', 'thereupon', 'hence', 'front', 're', 'hers', 'whoever', 'computer', 'already', 'must', 'are', 'using', 'over', 'sixty', 'off', 'often', 'she', 'and', 'before', 'done', 'forty', 'well', 'nowhere', 'up', 'this', 'amongst', 'describe', 'whence', 'latterly', 'whenever', 'meanwhile', 'bottom', 'there', 'noone', 'whom', 'few', 'twelve', 'back', 'along', 'each', 'them', 'via', 'now', 'an', 'when', 'mostly', 'beside', 'where', 'myself', 'might', 'afterwards', 'less', 'cry', 'that', 'become', 'should', 'another', 'alone', 'hereby', 'were', 'because', 'serious', 'have', 'cant', 'throughout', 'am', 'whereby', 'these', 'hereupon', 'behind', 'so', 'ourselves', 'may', 'kg', 'together', 'no', 'all', 'somehow', 'becoming', 'be', 'thus', 'wherever', 'mill', 'would', 'ie', 'give', 'whole', 'either', 'how', 'the', 'you', 'don', 'per', 'had', 'onto', 'of', 'ltd', 'many', 'amoungst', 'perhaps', 'such', 'take', 'whose', 'a', 'cannot', 'twenty', 'it', 'two', 'into', 'anyone', 'seeming', 'rather', 'except', 'former', 'mine', 'could', 'besides', 'system', 'interest', 'six', 'his', 'least', 'by', 'most', 'or', 'go', 'after', 'thereby', 'nor', 'bill', 'more', 'see', 'among', 'therein', 'couldnt', 'doing', 'full', 'others', 'though', 'while', 'towards', 'me', 'just', 'everything', 'whether', 'even', 'our', 'etc', 'upon', 'everyone', 'un', 'do', 'moreover', 'didn', 'own', 'toward', 'why', 'also', 'else', 'somewhere', 'out', 'sincere', 'find', 'elsewhere', 'can', 'please', 'fifty', 'one', 'anything', 'anyway', 'yet', 'eleven', 'becomes', 'which', 'once', 'from', 'eight', 'third', 'only', 'something', 'thence', 'enough', 'thin', 'but', 'during', 'thick', 'therefore', 'been', 'again', 'detail', 'below', 'as', 'still', 'he', 'to', 'herein', 'latter', 'they', 'almost', 'eg', 'part', 'nobody', 'what', 'four', 'ever', 'beforehand', 'itself', 'other', 'several', 'is', 'unless', 'whereafter', 'whither', 'your', 'indeed', 'put', 'for', 'those', 'seemed', 'anyhow', 'her', 'due', 'about', 'with', 'beyond', 'being', 'quite', 'five', 'in', 'top', 'whatever', 'herself', 'since', 'seem', 'on', 'hasnt', 'did', 'its', 'without', 'very', 'always', 'within', 'last', 'their', 'us', 'who', 'found', 'move', 'nothing', 'nevertheless', 'against', 'keep', 'none', 'above', 'whereupon', 'formerly', 'anywhere', 'much', 'first'})\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "print(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ecf961f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:33:26.552279Z",
     "start_time": "2022-05-10T03:33:26.521883Z"
    },
    "id": "8ecf961f",
    "outputId": "c458965d-50a4-4462-8868-f51c54e4a0f2"
   },
   "outputs": [],
   "source": [
    "# customized stopword list by adding common but not useful words\n",
    "\n",
    "stopword_list = set(list(stopwords.words('english'))+list(STOPWORDS)).\\\n",
    "union({ 'would',  'really', '-' , 'even', 'hotel', 'UK', 'U.K.', 'well', 'able', 'try', 'tried', 'definitely', 'actual', \n",
    "       'actually', 'addional', 'additionally', 'absolutely', 'anymore', 'apparently', 'basically', 'received',\n",
    "       'completely', 'extremely', 'generally', 'hello', 'anymore', 'definitely', 'finally', 'honestly', \n",
    "       'just', 'lol', 'literally', 'item', 'oh','ok','okay','r','thank','thanks','thing','yes','yeah',\n",
    "       'maybe', 'mean', 'mention', 'mind', 'need', 'normal', 'normally', 'opinion', 'overall', 'people', 'person',\n",
    "       'personally', 'probably', 'recieved', 'saw', 'simply', 'somewhat', 'think', 'thought', 'totally', 'truly',\n",
    "       'usually', 'want', 'wow', 'www', 'wo', 'slight', 'slightly', 'allow','apply','arrive','ask','ate','available',\n",
    "       'away','bring','care','carry', 'certainly','com','come','consider','decide','discover','especially','exactly',\n",
    "       'expect', 'feel','felt','general','gp','href','http','let','make','agree', 'believe', 'super','little',\n",
    "      'thankyou', 'exceedingly', 'everything', 'mmmm', 'unfortunately'})\n",
    "\n",
    "# keep privatives as they are useful when adding sequence into consideration in N-gram language model\n",
    "\n",
    "keep_stopwords = ['not', \"don't\", 'no', \"doesn't\", 'doesn', 'cannot', \"mightn't\", \"can't\", 'without', \"didn't\", \n",
    "                 \"haven't\", 'cant', \"hasn't\", \"weren't\", 'wouldn', 'neither', \"wouldn't\", \"isn't\", 'didn', \"mustn't\",\n",
    "                 \"shouldn't\", \"needn't\", 'weren', \"couldn't\", 'don', 'aren', \"aren't\", \n",
    "                 'couldn', 'couldnt', 'hadn', 'haven', 'shouldn', 'wasn', \"wasn't\", 'won', \"won't\"]\n",
    "stopword_list.difference_update(keep_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37687685",
   "metadata": {
    "id": "37687685"
   },
   "source": [
    "## Positive Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ece7c9e",
   "metadata": {
    "id": "8ece7c9e"
   },
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "\n",
    "lemm_positive = []\n",
    "\n",
    "for i in hotel['Positive_Review_Clean']:\n",
    "    lemm_positive.append(lemmatize_sentence(i))\n",
    "    \n",
    "hotel['lemm_positive'] = lemm_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d62ad21",
   "metadata": {
    "id": "3d62ad21"
   },
   "outputs": [],
   "source": [
    "hotel['positive_remove_stopwords'] = remove(hotel['lemm_positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5dc54a",
   "metadata": {
    "id": "5b5dc54a"
   },
   "outputs": [],
   "source": [
    "# regex grouping\n",
    "\n",
    "clean_text = [] \n",
    "replacement = [\n",
    "    (r'comf(?:y|ortable)', 'comfortable'),\n",
    "    (r'min(?:ute)?', 'minute'),\n",
    "    (r'helpful(?:l)?', 'helpful'), \n",
    "    (r'welcom(?:e|ing|inuteg)?', 'welcome')\n",
    "]\n",
    "\n",
    "for line in hotel['positive_remove_stopwords']:\n",
    "    for pattern, word in replacement:  \n",
    "        line = re.sub(pattern, word, line)\n",
    "    clean_text.append(line)\n",
    "\n",
    "hotel['positive_regex'] = clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bb2825",
   "metadata": {},
   "source": [
    "### Further handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67971e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common words\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "counter=Counter()\n",
    "for review in hotel['positive_regex']:\n",
    "    words = nltk.word_tokenize(review)  \n",
    "    for word in words:\n",
    "        counter[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29ea2399",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount=list(counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a32b303f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb98194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "commonword=pd.read_csv('20k.txt')\n",
    "common=commonword.values.reshape(-1,).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1394b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongspell=[]\n",
    "for word in wordcount:\n",
    "    if word in common:\n",
    "        continue\n",
    "    else:\n",
    "        wrongspell.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146135cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(wrongspell).to_excel('wrong_spell_pos.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "879623dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex grouping wrong spelling\n",
    "\n",
    "clean_text = [] \n",
    "replacement = [\n",
    "    (r'\\b(\\w+)?\\d+(\\w+)?\\b','_NUMBER_'),\n",
    "    (r'\\bdis(?:s)?ap(?:p)?(?:o)?(?:i)?(?:n)?t(?:ed|ing)?\\b','disappoint'),\n",
    "    (r'surp(?:p|r)?ise(?:d|ing)?', 'surprise'),\n",
    "    (r'\\beveveryone\\b', 'everyone'),\n",
    "    (r'\\babosultely|absolutly\\b', 'absolutely'),\n",
    "    (r'\\bunfortunatly\\b', 'unfortunately'),\n",
    "    (r'\\benviroment|invironment\\b', 'environment'),\n",
    "    (r'\\bbadroom\\b', 'bedroom'),\n",
    "    (r'\\bwelcomering|wecominuteg\\b', 'welcoming'),\n",
    "    (r'\\bo(?:o)?stpark', 'oosterpark'),\n",
    "    (r'\\bne(?:s|ss)?presso(?:s)?|expresso|coffe(?:e)?\\b', 'espresso'),\n",
    "    (r'\\btrafic\\b', 'traffic'),\n",
    "    (r'\\bflavour\\b', 'flavor'),\n",
    "    (r'\\balresdy\\b', 'already'),\n",
    "    (r'\\bsmokinh\\b', 'smoking'),\n",
    "    (r'\\brefebishment|refurbisging\\b', 'refurbishment'),\n",
    "    (r'\\bhe(?:a)?l(?:p|o)?(?:e)?ful(?:l)?\\b', 'helpful'),\n",
    "    (r'\\bextre(?:a)?(?:m)?(?:em)?ly|extreamly|extremley|extrememy\\b', 'extremely'),\n",
    "    (r'\\bprofesional\\b', 'proffesional'),\n",
    "    (r'\\bsuper{1,}b\\b', 'superb'),\n",
    "    (r'\\bdelious\\b', 'delicious'),\n",
    "    (r'\\bavaiable\\b', 'available'),\n",
    "    (r'\\bchocolat\\b', 'chocolate'),\n",
    "    (r'\\babsoulty|absoulte\\b', 'absolute'),\n",
    "    (r'\\bpleasently\\b', 'pleasantly'),\n",
    "    (r'\\bbriliant\\b', 'brilliant'),\n",
    "    (r'\\bsomehwere\\b', 'somewhere'),\n",
    "    (r'\\bawsome\\b', 'awesome'),\n",
    "    (r'\\bminutei\\b', 'mini'),\n",
    "    (r'\\bminuteibar\\b', 'minibar'),\n",
    "    (r'\\bminuteimalist\\b', 'minimalist'),\n",
    "    (r'\\bhelpfulnes\\b', 'helpfulness'),\n",
    "    (r'\\bhelpfulnes\\b', 'helpfulness'),\n",
    "    (r'\\btasy\\b', 'tasty'),\n",
    "    (r'\\bluxuorios\\b', 'luxurious'),\n",
    "    (r'\\bbedr(?:r|o)om(?:s)?\\b', 'bedroom'),\n",
    "    (r'\\byoghurt\\b', 'yogurt'),\n",
    "    (r'\\blovley\\b', 'lovely'),\n",
    "    (r'\\bwvery\\b', 'very'),\n",
    "    (r'\\bvarierty\\b', 'variety'),\n",
    "    (r'\\bdiscrepcy\\b', 'discrepancy'),\n",
    "    (r'\\bwonderfulf\\b', 'wonderful'),\n",
    "    (r'\\boveral{1,}\\b', 'overalll'),\n",
    "    (r'\\barrrived\\b', 'arrived'),\n",
    "    (r'\\buncomftable\\b', 'uncomfortable'),\n",
    "    (r'\\befficent\\b', 'efficient'),\n",
    "    (r'\\btallkiing\\b', 'talking'),\n",
    "    (r'\\bevrything\\b', 'everything'),\n",
    "    (r'\\bfsmily\\b', 'smily'),\n",
    "    (r'\\bftrsnsport\\b', 'transport'),\n",
    "    (r'\\btouble\\b', 'trouble'),\n",
    "    (r'\\bspacey\\b', 'spacy'),\n",
    "    (r'\\bswimminutegpool\\b', 'swimmingpool'),\n",
    "    (r'\\barrrival\\b', 'arrival'),\n",
    "    (r'\\bso{1,}\\b', 'so'),\n",
    "    (r'\\bwelll\\b', 'well'),\n",
    "    (r'\\bfanatastic\\b', 'fantastic'),\n",
    "    (r'\\bintially\\b', 'initially'),\n",
    "    (r'\\bresepction\\b', 'reception'),\n",
    "    (r'\\bproffesionally\\b', 'professionally'),\n",
    "    (r'\\bhaply\\b', 'happy'),\n",
    "    (r'\\bwslking\\b', 'walking'),\n",
    "    (r'\\bsomethings\\b', 'something'),\n",
    "    (r'\\bminuteimise|minuteiute\\b', 'minute'),\n",
    "    (r'\\bathmosphe\\b', 'athmosphere'),\n",
    "    (r'\\bimpresssively\\b', 'impressively'),\n",
    "    (r'\\bneeed\\b', 'need'),\n",
    "    (r'\\bconsiderng\\b', 'considering'),\n",
    "    (r'\\bclosenes\\b', 'closeness'),\n",
    "    (r'\\bminuteiature\\b', 'miniature'),\n",
    "    (r'\\bcleaness\\b', 'cleanness'),\n",
    "    (r'\\bthouight\\b', 'thought'),\n",
    "    (r'\\bstunnig\\b', 'stunning'),\n",
    "    (r'\\barcatecture\\b', 'architecture'),\n",
    "    (r'\\bmusuem\\b', 'museum'),\n",
    "    (r'\\bamamzing|amazing{0,}|anazing\\b', 'amazing'),\n",
    "    (r'\\bprobaly\\b', 'probably'),\n",
    "    (r'\\bthrougout\\b', 'througout'),\n",
    "    (r'\\bpoplar\\b', 'popular'),\n",
    "    (r'\\bofferred\\b', 'offer'),\n",
    "    (r'\\bdeterminutee\\b', 'determine'),\n",
    "    (r'\\bfunjy\\b', 'funny'),\n",
    "    (r'\\bcostumer\\b', 'customer'),\n",
    "    (r'\\bprefereed\\b', 'prefer'),\n",
    "    (r'\\bminuteinal\\b', 'mininal'),\n",
    "    (r'\\binmediately\\b', 'immediately'),\n",
    "    (r'\\bhamman\\b', 'hammam'),\n",
    "    (r'\\bbettter\\b', 'better'),\n",
    "    (r'\\boffen\\b', 'often'),\n",
    "    (r'\\bgoed\\b', 'good'),\n",
    "    (r'\\blitte\\b', 'little'),\n",
    "    (r'\\bnatutal\\b', 'natural'),\n",
    "    (r'\\bpoilite\\b', 'polite'),\n",
    "    (r'\\beledely\\b', 'elderly'),\n",
    "    (r'\\bmemnbers\\b', 'members'),\n",
    "    (r'\\bperfeect\\b', 'perfect'),\n",
    "    (r'\\bsrvice\\b', 'service'),\n",
    "    (r'\\bpowerfull\\b', 'powerful'),\n",
    "    (r'\\bunderwhelminuteg\\b', 'underwhelming'),\n",
    "    (r'\\bcheep\\b', 'cheap'),\n",
    "    (r'\\bparticuarly\\b', 'particularly'),\n",
    "    (r'\\bmahine\\b', 'machine'),\n",
    "    (r'\\bplastc\\b', 'plastic'),\n",
    "    (r'\\bperfecto\\b', 'perfect'),\n",
    "    (r'\\bbr{1,}illiant\\b', 'brilliant'),\n",
    "    (r'\\bieverywhere\\b', 'everywhere'),\n",
    "    (r'\\bgreate|greating\\b', 'greet'),\n",
    "    (r'\\bmorden|mordern|moderness\\b', 'modern'),\n",
    "    (r'\\bconviently|convenieny|convienient|convieniaces|convinence|convieniaces\\b', 'convenient'),\n",
    "    (r'\\bspacous|spaceous\\b', 'spacious'),\n",
    "    (r'\\bpositon|possition|positon\\b', 'position'),\n",
    "    (r'\\batmosphere{0,}|atmerphere|atmerphere\\b', 'atmosphere'),\n",
    "    (r'\\bhelpfuly|helpf\\b', 'helpful'),\n",
    "    (r'\\bacomadating|accomadating|accomdation|accomadate\\b', 'accommodate'),\n",
    "    (r'\\brecomend|reccomend|recomand|reccommend|recomened|recccomend|reccomendations\\b', 'recommend'),\n",
    "    (r'\\bcleanessnes|clenliness|cleanlness\\b', 'cleanness'),\n",
    "    (r'\\bbeutiful|beatiful|beuatiful|beautifull|beatufuil|beatifull|beauitful\\b', 'beautiful'),\n",
    "    (r'\\bcomfey|comphy|comfty|comftable|confortable|confy|counfy|cmfy|confort|compfy|comforatble|\\\n",
    "    comfprtable|comforable|vomfortable|comferable|comfortsble|comftorbale|comfotable|comfie|comfortabl|confttable|\\\n",
    "    comfortablew|conformable\\b', 'comfortable'),\n",
    "    (r'\\bllocation|locatiom|lcation|locarion|loction|locution|iocation|lovation|kocation\\b', 'location'),\n",
    "    (r'\\bbarthroom|barhroom|bathrooom|bagroom|bathtroom\\b', 'bathroom'),\n",
    "    (r'\\bqueit|quinet\\b', 'quiet'),\n",
    "    (r'\\breminuteiscent\\b', 'reminiscent'),\n",
    "    (r'\\bexcellnt|excellant|eccellent|ecellent|excellen|excelleny\\b', 'excellent'),\n",
    "    (r'\\bthebreakfast|brekfast|beakfast|breakfadt|beeakfast|breskfast|breakfasy|brakefeast\\b', 'breakfast'),\n",
    "    (r'\\brestaraunt|restorant|restraunts|resteraunt|resteraunt|resturant|resataurant|reastraunts|restaurante|\\\n",
    "     restsurant|restruants|restaraunts|restuarants|resturants|restraunt|restaurent|resturaunt|testaurant\\b', \\\n",
    "     'restaurant'),\n",
    "    (r'\\boverwhelminuteg|overwhelminutegly|overwhelm|overwhelminutegly\\b', 'overwhelming'),\n",
    "    (r'\\bwestminutester|westminuteister|westmister|westminuteter\\b', 'westminster'),\n",
    "    (r'\\bfacilties|facilities\\b', 'facility'),\n",
    "    (r'\\bmony|mmmm\\b', 'many'),\n",
    "    (r'\\bveiw|viiew\\b', 'view'),\n",
    "    (r'\\bdefinatly|defintely|definetly|definetley|deffinately|definateley|definetely\\b', 'definitely'),\n",
    "    (r'\\bexellent|rxcellent|ecellent\\b', 'excellet'),\n",
    "    (r'\\bfrendly|fiendly|freindly|friandly|frielndly|friendlly|friendless|friendeliness|friwndly|feiendly|\\\n",
    "    frindly\\b', 'friendly'),\n",
    "    (r'\\beverthing|wverything|everything{0,}|everytjing|evrerthing|everuthing\\b', 'everything'),\n",
    "    (r'\\brecepti0nist|receptionest|receptionnist|recptionist\\b', 'receptionist'),\n",
    "    (r'\\bfantasics|fantatic|fantatsic\\b', 'fantastic'),\n",
    "    (r'\\battentative|attentetive\\b', 'attentive'),\n",
    "    (r'\\bprossecco|procesco\\b', 'prosseco'),\n",
    "    (r'\\bunerground|undergraound|ununderground|nearunderground\\b', 'underground')\n",
    "]\n",
    "\n",
    "for line in hotel['positive_regex']:\n",
    "    for pattern, word in replacement:  \n",
    "        line = re.sub(pattern, word, line)\n",
    "    clean_text.append(line)\n",
    "\n",
    "hotel['positive_regex'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26c87240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords again\n",
    "\n",
    "hotel['positive_regex'] = remove(hotel['positive_regex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0caa0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex to reduce overlaps in topic modeling\n",
    "\n",
    "clean_text = [] \n",
    "replacement = [\n",
    "    (r'\\bhelpfulness\\b', 'helpful'),\n",
    "    (r'\\bdisppointed|disppoints|disappointing\\b', 'disappoint'),\n",
    "    (r'\\bmodernise|modernize\\b', 'modern'),\n",
    "    (r'\\bpricey\\b', 'expensive'),\n",
    "    (r'\\beatery\\b', 'restaurant'),\n",
    "    (r'\\bpoliteness\\b', 'polite'),\n",
    "    (r'\\bspacy\\b', 'spacious'),\n",
    "    (r'\\brefurb(?:ed|ing)?|refurbish(?:ing)?|refurnish\\b', 'refurbish'),\n",
    "    (r'\\breceptionist(?:s)?|receptive\\b', 'reception'),\n",
    "    (r'\\bfriendlyness\\b', 'friendly'),\n",
    "    (r'\\bcouldn(?:t)?\\b', 'couldnt'),\n",
    "    (r'\\bwouldn(?:t)?\\b', 'couldnt'),\n",
    "    (r'\\battentive(?:ly)?\\b', 'attentive'),\n",
    "    (r'\\baccomodation(?:s)?\\b', 'accomodation'),\n",
    "    (r'\\bclean(?:ness)?\\b', 'clean'),\n",
    "    (r'\\bprofessional(?:ly)?\\b', 'professional'),\n",
    "    (r'\\bcelebratory|congratulatory\\b', 'celebrate'),\n",
    "    (r'\\bconvenient(?:ly)?|convenience\\b', 'convenient'),\n",
    "    (r'\\bcomfort(?:ing|ness|able{0,})?|comfortably|comfortability\\b', 'comfortable'),\n",
    "    (r'\\bsurprise(?:ing|d)?\\b', 'surprise'),\n",
    "    (r'\\bgood|excellent|great|nice|wonderful|marvellous|amazing|fantastic|perfect(ion)?|awesome|\\\n",
    "    stunningly|brilliantly|unbelievably|amaze|amazing|stun|excellently|exceptionallly|brilliant|impressively|\\\n",
    "    outstandingly|incredibly\\b', 'good'),\n",
    "    (r'\\bgoodtt\\b', 'good')\n",
    "]\n",
    "\n",
    "for line in hotel['positive_regex']:\n",
    "    for pattern, word in replacement:  \n",
    "        line = re.sub(pattern, word, line)\n",
    "    clean_text.append(line)\n",
    "\n",
    "hotel['positive_regex_further'] = clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d6271c",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b31aefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
    "\n",
    "vectorizer_3 = TfidfVectorizer(ngram_range=(3,3), \n",
    "                               token_pattern=r'\\b\\w\\w+\\b',\n",
    "                               min_df=5, \n",
    "                               # max_df=0.1,\n",
    "                               # max_features= 10000\n",
    "                               ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef1aba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_positive = list(hotel['positive_regex_further'].values)\n",
    "\n",
    "X_further = vectorizer_3.fit_transform(corpus_positive)\n",
    "terms = vectorizer_3.get_feature_names()\n",
    "tf_idf_positive_3 = pd.DataFrame(X_further.toarray().transpose(), index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fc3c965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>124871</th>\n",
       "      <th>124872</th>\n",
       "      <th>124873</th>\n",
       "      <th>124874</th>\n",
       "      <th>124875</th>\n",
       "      <th>124876</th>\n",
       "      <th>124877</th>\n",
       "      <th>124878</th>\n",
       "      <th>124879</th>\n",
       "      <th>124880</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ _number_</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ adult</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ bed</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ breakfast</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_number_ _number_ central</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old grandson</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year old son</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young lady check</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young lady reception</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young man reception</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14695 rows Ã— 124881 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0       1       2       3       4       5       \\\n",
       "_number_ _number_ _number_      0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ adult         0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ bed           0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ breakfast     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ central       0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...                             ...     ...     ...     ...     ...     ...   \n",
       "year old grandson               0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "year old son                    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "young lady check                0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "young lady reception            0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "young man reception             0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                             6       7       8       9       ...  124871  \\\n",
       "_number_ _number_ _number_      0.0     0.0     0.0     0.0  ...     0.0   \n",
       "_number_ _number_ adult         0.0     0.0     0.0     0.0  ...     0.0   \n",
       "_number_ _number_ bed           0.0     0.0     0.0     0.0  ...     0.0   \n",
       "_number_ _number_ breakfast     0.0     0.0     0.0     0.0  ...     0.0   \n",
       "_number_ _number_ central       0.0     0.0     0.0     0.0  ...     0.0   \n",
       "...                             ...     ...     ...     ...  ...     ...   \n",
       "year old grandson               0.0     0.0     0.0     0.0  ...     0.0   \n",
       "year old son                    0.0     0.0     0.0     0.0  ...     0.0   \n",
       "young lady check                0.0     0.0     0.0     0.0  ...     0.0   \n",
       "young lady reception            0.0     0.0     0.0     0.0  ...     0.0   \n",
       "young man reception             0.0     0.0     0.0     0.0  ...     0.0   \n",
       "\n",
       "                             124872  124873  124874  124875  124876  124877  \\\n",
       "_number_ _number_ _number_      0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ adult         0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ bed           0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ breakfast     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "_number_ _number_ central       0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...                             ...     ...     ...     ...     ...     ...   \n",
       "year old grandson               0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "year old son                    0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "young lady check                0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "young lady reception            0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "young man reception             0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "                             124878  124879  124880  \n",
       "_number_ _number_ _number_      0.0     0.0     0.0  \n",
       "_number_ _number_ adult         0.0     0.0     0.0  \n",
       "_number_ _number_ bed           0.0     0.0     0.0  \n",
       "_number_ _number_ breakfast     0.0     0.0     0.0  \n",
       "_number_ _number_ central       0.0     0.0     0.0  \n",
       "...                             ...     ...     ...  \n",
       "year old grandson               0.0     0.0     0.0  \n",
       "year old son                    0.0     0.0     0.0  \n",
       "young lady check                0.0     0.0     0.0  \n",
       "young lady reception            0.0     0.0     0.0  \n",
       "young man reception             0.0     0.0     0.0  \n",
       "\n",
       "[14695 rows x 124881 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_positive_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c7bd53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>staff friendly helpful</th>\n",
       "      <td>1155.073150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendly helpful staff</th>\n",
       "      <td>742.693326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good location good</th>\n",
       "      <td>606.846644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comfortable bed good</th>\n",
       "      <td>523.510775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staff helpful friendly</th>\n",
       "      <td>517.824689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helpful bed comfortable</th>\n",
       "      <td>49.712669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location good easy</th>\n",
       "      <td>49.671534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extra comfortable bed</th>\n",
       "      <td>49.358209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good size bed</th>\n",
       "      <td>48.714237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast good lot</th>\n",
       "      <td>48.702859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               score\n",
       "staff friendly helpful   1155.073150\n",
       "friendly helpful staff    742.693326\n",
       "good location good        606.846644\n",
       "comfortable bed good      523.510775\n",
       "staff helpful friendly    517.824689\n",
       "...                              ...\n",
       "helpful bed comfortable    49.712669\n",
       "location good easy         49.671534\n",
       "extra comfortable bed      49.358209\n",
       "good size bed              48.714237\n",
       "breakfast good lot         48.702859\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_positive_3 = tf_idf_positive_3.sum(axis = 1) \n",
    "score_positive_3 = pd.DataFrame(tf_idf_positive_3, columns=[\"score\"])\n",
    "score_positive_3.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "top = score_positive_3.head(300)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f2b1ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top.index).to_excel('tfidf_pos.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a247fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liujinglei/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X positive is (124881, 14695)\n",
      "Decomposed W positive matrix is (124881, 2)\n",
      "Decomposed H positice matrix is (2, 14695)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=2)\n",
    "W_positive = nmf.fit_transform(X_further)\n",
    "H_positive = nmf.components_\n",
    "print(f\"Original shape of X positive is {X_further.shape}\")\n",
    "print(f\"Decomposed W positive matrix is {W_positive.shape}\") \n",
    "print(f\"Decomposed H positice matrix is {H_positive.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1afe5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def get_top_tf_idf_tokens_for_topic(H: np.array, feature_names: List[str], num_top_tokens: int = 5):\n",
    "  \"\"\"\n",
    "  Uses the H matrix (K components x M original features) to identify for each\n",
    "  topic the most frequent tokens.\n",
    "  \"\"\"\n",
    "  for topic, vector in enumerate(H):\n",
    "    print(f\"TOPIC {topic}\\n\")\n",
    "    total = vector.sum()\n",
    "    top_scores = vector.argsort()[::-1][:num_top_tokens] \n",
    "    token_names = list(map(lambda idx: feature_names[idx], top_scores))\n",
    "    strengths = list(map(lambda idx: vector[idx] / total, top_scores))\n",
    "    \n",
    "    for strength, token_name in zip(strengths, token_names):\n",
    "        print(f\"\\b{token_name} ({round(strength * 100, 1)}%)\\n\")\n",
    "    print(f\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "923e7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tf_idf = pd.DataFrame(X_further.toarray(), columns=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tf_idf_drop = positive_tf_idf.drop(['friendly helpful staff', 'good location friendly', 'location friendly staff', 'friendly helpful stay', \\\n",
    "    'staff good location', 'helpful staff good', 'staff good modern', 'location friendly helpful', 'friendly helpful time', 'helpful staff lot', 'good location goodly', \\\n",
    "        'friendly helpful trouble', 'helpful staff not', 'staff good professional', 'location good base', 'staff friendly oblige', \\\n",
    "            'friendly staff help', 'staff good roof', 'good friendly staff', 'staff good selection', 'staff good soon',\n",
    "                'staff good recommend', 'good staff member', 'helpful staff speak', 'staff good rooftop', 'good staff not', 'location good decor', 'staff good size'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57326834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\bstaff friendly offer (27.4%)\n",
      "\n",
      "\bgood staff leave (2.1%)\n",
      "\n",
      "\bfriendly helpful room (1.6%)\n",
      "\n",
      "\bfriendly helpful good (1.1%)\n",
      "\n",
      "\bcomfortable staff friendly (1.1%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bfriendly helpful upgrade (21.6%)\n",
      "\n",
      "\bgood location heart (3.2%)\n",
      "\n",
      "\bhelpful staff leave (3.2%)\n",
      "\n",
      "\bstaff good quiet (2.9%)\n",
      "\n",
      "\blocation good beautiful (2.8%)\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_top_tf_idf_tokens_for_topic(H_positive, positive_tf_idf_drop.columns.tolist(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6df57b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_top_documents_for_each_topic(W: np.array, documents: List[str], num_docs: int = 5):\n",
    "    sorted_docs = W.argsort(axis=0)[::-1]\n",
    "    top_docs = sorted_docs[:num_docs].T\n",
    "    per_document_totals = W.sum(axis=1)\n",
    "    for topic, top_documents_for_topic in enumerate(top_docs):\n",
    "        print(f\"Topic {topic}\")\n",
    "        for doc in top_documents_for_topic:\n",
    "            score = W[doc][topic]\n",
    "            percent_about_topic = round(score / per_document_totals[doc] * 100, 1)\n",
    "            print(f\"{percent_about_topic}%\", documents[doc])\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8634c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "100.0% staff friendly helpful \n",
      "100.0% staff friendly helpful tiny room creatively appoint good bathroom food breakfast limit good quality bar facility lobby lovely touch \n",
      "100.0% staff friendly helpful \n",
      "100.0% staff friendly helpful pleasant \n",
      "100.0% staff friendly helpful \n",
      "Topic 1\n",
      "100.0% friendly helpful staff \n",
      "100.0% friendly helpful staff \n",
      "100.0% good standard friendly helpful staff \n",
      "100.0% cleanliness friendly helpful staff \n",
      "100.0% friendly helpful staff \n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_top_documents_for_each_topic(W_positive, hotel['positive_regex_further'].tolist(), num_docs=5)\n",
    "\n",
    "# some examples from the documents showing why there is too much overlap between the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f07aab4",
   "metadata": {},
   "source": [
    "many reviewers mention about both staff and location as well as the room in their positive reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e934a0d",
   "metadata": {
    "id": "6e934a0d"
   },
   "source": [
    "## Negative Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9989e84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:36:47.994915Z",
     "start_time": "2022-05-10T03:33:34.789990Z"
    },
    "id": "e9989e84",
    "outputId": "80eba73d-d719-45f4-999d-4ef4a518a959"
   },
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "\n",
    "lemm_negative = []\n",
    "\n",
    "for i in hotel['Negative_Review_Clean']:\n",
    "    lemm_negative.append(lemmatize_sentence(i))\n",
    "    \n",
    "hotel['lemm_negative'] = lemm_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ad46b29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T03:37:08.881509Z",
     "start_time": "2022-05-10T03:36:51.055629Z"
    },
    "id": "4ad46b29"
   },
   "outputs": [],
   "source": [
    "hotel['negative_remove_stopwords'] = remove(hotel['lemm_negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2c0c904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:05:03.136383Z",
     "start_time": "2022-05-10T07:04:59.755838Z"
    },
    "id": "e2c0c904"
   },
   "outputs": [],
   "source": [
    "# regex grouping\n",
    "\n",
    "clean_text = [] \n",
    "replacement = [\n",
    "    (r'\\b(?:little|bit)\\b', 'little'),\n",
    "    (r'\\bair(?:\\scondition(?:er|ing)?)?(?:\\sunit)?\\b','air_conditioner'),\n",
    "    (r'\\bnot\\sinclude\\b','not include'),\n",
    "    (r'\\bcentre\\b','center'),\n",
    "    (r'\\bmachine\\b', 'facility'),\n",
    "    (r'\\bwi\\sfi\\b','wifi'),\n",
    "    (r'\\bcomfy\\b','comfortable'),\n",
    "    (r'\\bfirm\\b','hard'),\n",
    "    (r'\\b(?:tea\\s)?(?:coffee\\s)?(?:making\\s)?facility\\b','drink_facility'),\n",
    "    (r'\\btea\\scoffee\\b','tea_coffee')\n",
    "]\n",
    "\n",
    "for line in hotel['negative_remove_stopwords']:\n",
    "    for pattern, word in replacement:  \n",
    "        line = re.sub(pattern, word, line)\n",
    "    clean_text.append(line)\n",
    "\n",
    "hotel['negative_regex'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1edb0bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:05:16.037220Z",
     "start_time": "2022-05-10T07:05:15.307040Z"
    },
    "id": "d1edb0bd"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer   \n",
    "\n",
    "vectorizer_3 = TfidfVectorizer(ngram_range=(3,3), \n",
    "                               token_pattern=r'\\b\\w\\w+\\b', \n",
    "                               min_df=3,\n",
    "                               # max_features= 6000,  \n",
    "                               stop_words=stopword_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caa636c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:05:33.932480Z",
     "start_time": "2022-05-10T07:05:29.854749Z"
    },
    "id": "caa636c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liujinglei/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['hadn', 'uk'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "corpus_negative = list(hotel['negative_regex'].values)\n",
    "\n",
    "X_neg = vectorizer_3.fit_transform(corpus_negative)\n",
    "terms = vectorizer_3.get_feature_names()\n",
    "tf_idf_negative_3 = pd.DataFrame(X_neg.toarray().transpose(), index=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e6e5ab16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:07:33.174423Z",
     "start_time": "2022-05-10T07:06:17.583989Z"
    },
    "id": "e6e5ab16"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no drink_facility room</th>\n",
       "      <td>216.678175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breakfast not include</th>\n",
       "      <td>148.014629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no hot water</th>\n",
       "      <td>119.329142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bed not comfortable</th>\n",
       "      <td>110.894606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_conditioner didn work</th>\n",
       "      <td>99.853642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price mini bar</th>\n",
       "      <td>18.595718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no big deal</th>\n",
       "      <td>18.524104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not _number_ _number_</th>\n",
       "      <td>18.467287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wait _number_ hour</th>\n",
       "      <td>18.444752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window fresh air_conditioner</th>\n",
       "      <td>18.418586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   score\n",
       "no drink_facility room        216.678175\n",
       "breakfast not include         148.014629\n",
       "no hot water                  119.329142\n",
       "bed not comfortable           110.894606\n",
       "air_conditioner didn work      99.853642\n",
       "...                                  ...\n",
       "price mini bar                 18.595718\n",
       "no big deal                    18.524104\n",
       "not _number_ _number_          18.467287\n",
       "wait _number_ hour             18.444752\n",
       "window fresh air_conditioner   18.418586\n",
       "\n",
       "[300 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_negative_3 = tf_idf_negative_3.sum(axis = 1) \n",
    "score_negative_3 = pd.DataFrame(tf_idf_negative_3, columns=[\"score\"])\n",
    "score_negative_3.sort_values(by=\"score\", ascending=False, inplace=True)\n",
    "top_neg = score_negative_3.head(300)\n",
    "top_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22699fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:07:46.403899Z",
     "start_time": "2022-05-10T07:07:46.379693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21539"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_negative_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "017dc066",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T06:42:24.828076Z",
     "start_time": "2022-05-10T06:42:24.828042Z"
    },
    "id": "017dc066"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(top_neg.index).to_excel('tfidf_neg.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5a5c5a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:07:58.305400Z",
     "start_time": "2022-05-10T07:07:55.731025Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liujinglei/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of X negative is (124881, 21539)\n",
      "Decomposed W negative matrix is (124881, 3)\n",
      "Decomposed H negative matrix is (3, 21539)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf = NMF(n_components=3)\n",
    "W_neg = nmf.fit_transform(X_neg)\n",
    "H_neg = nmf.components_\n",
    "print(f\"Original shape of X negative is {X_neg.shape}\")\n",
    "print(f\"Decomposed W negative matrix is {W_neg.shape}\") # verify shape\n",
    "print(f\"Decomposed H negative matrix is {H_neg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34cc4b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:08:09.752391Z",
     "start_time": "2022-05-10T07:08:09.297874Z"
    }
   },
   "outputs": [],
   "source": [
    "neg_tf_idf = pd.DataFrame(X_neg.toarray(), columns=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b00b1e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T07:08:30.092870Z",
     "start_time": "2022-05-10T07:08:30.076882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "\n",
      "\bno drink_facility room (60.0%)\n",
      "\n",
      "\bdrink_facility room no (1.0%)\n",
      "\n",
      "\broom no drink_facility (0.7%)\n",
      "\n",
      "\bdrink_facility room room (0.6%)\n",
      "\n",
      "\bdisappoint no drink_facility (0.5%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 1\n",
      "\n",
      "\bbreakfast not include (43.1%)\n",
      "\n",
      "\bnot include price (8.9%)\n",
      "\n",
      "\bnot include expensive (2.3%)\n",
      "\n",
      "\bnot include room (1.5%)\n",
      "\n",
      "\bnot include book (1.3%)\n",
      "\n",
      "==================================================\n",
      "TOPIC 2\n",
      "\n",
      "\bbed not comfortable (36.7%)\n",
      "\n",
      "\bsmall bed not (1.6%)\n",
      "\n",
      "\bsofa bed not (1.5%)\n",
      "\n",
      "\bnot comfortable room (1.5%)\n",
      "\n",
      "\broom small bed (1.4%)\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "get_top_tf_idf_tokens_for_topic(H_neg,neg_tf_idf.columns.tolist(),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595f7b0",
   "metadata": {},
   "source": [
    "### further handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8df8598f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T06:23:42.887278Z",
     "start_time": "2022-05-11T06:23:24.959333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the most common words\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "counter=Counter()\n",
    "for review in hotel['negative_regex']:\n",
    "    words = nltk.word_tokenize(review)        \n",
    "    for word in words:\n",
    "        counter[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d57371c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19726"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount=list(counter.keys())\n",
    "\n",
    "type(wordcount)\n",
    "len(wordcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb00cda7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T06:33:46.010939Z",
     "start_time": "2022-05-11T06:33:45.972595Z"
    }
   },
   "outputs": [],
   "source": [
    "commonword=pd.read_csv('20k.txt')\n",
    "common=commonword.values.reshape(-1,).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73f3edbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T06:34:58.394000Z",
     "start_time": "2022-05-11T06:34:51.177252Z"
    }
   },
   "outputs": [],
   "source": [
    "wrongspell_neg=[]\n",
    "for word in wordcount:\n",
    "    if word in common:\n",
    "        continue\n",
    "    else:\n",
    "        wrongspell_neg.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f097b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T06:35:42.981168Z",
     "start_time": "2022-05-11T06:35:42.927240Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(wrongspell_neg).to_csv('wrong_spell_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "adda008c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:02:26.332721Z",
     "start_time": "2022-05-11T07:02:22.849650Z"
    }
   },
   "outputs": [],
   "source": [
    "# regex grouping\n",
    "import re\n",
    "clean_text = [] \n",
    "replacement = [\n",
    "    (r'\\b(\\w+)?\\d+(\\w+)?\\b','_NUMBER_'),\n",
    "    (r'\\bfilfy\\b','filthy'),\n",
    "    (r'\\bbre(aa)?kfast\\b', 'breakfast'),\n",
    "    (r'\\baak\\b','ask'),\n",
    "    (r'\\baap\\b','as soon as possible'),\n",
    "    (r'\\babso(u)?l(o)?ut(e)?l(e)?y\\b','absolutely'),\n",
    "    (r'\\baccom(m)?(?:a|o)?(d)?(?:e|a)?t(?:e(d)?|ing|ion|iin)\\b','accommadation')\n",
    "]\n",
    "\n",
    "for line in hotel['negative_regex']:\n",
    "    for pattern, word in replacement:  \n",
    "        line = re.sub(pattern, word, line)\n",
    "    clean_text.append(line)\n",
    "\n",
    "hotel['negative_regex'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c948f642",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T07:03:05.211103Z",
     "start_time": "2022-05-11T07:02:59.823285Z"
    }
   },
   "outputs": [],
   "source": [
    "hotel.to_csv('hotel_processing_new.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Data preprocessing-Copy1.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "9851e1369492554e682af8da439ce23d94f59fcc2cb07f7273af5455dce3c9c3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
